# Load the saved model and vectorizer
from joblib import load
import re
from nltk.corpus import stopwords

# Load your trained model and vectorizer
model = load('Notebooks/FakeNewsDetector.joblib')
vectorizer = load('Notebooks/Vectorizer.joblib')

# Load stopwords
stop_words = set(stopwords.words('english'))

def cleanText(text):
    """Clean text exactly the same way as during training"""
    text = str(text).lower()
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    words = text.split()
    words = [word for word in words if word not in stop_words]
    return " ".join(words)

def predict_news_fixed(text, clean_text=True):
    """
    Fixed prediction function - matches training preprocessing
    
    Args:
        text (str): Raw news article text
        clean_text (bool): Whether to clean the text (set to True for raw text)
    
    Returns:
        dict: Prediction details
    """
    # Clean the text only if it's raw (not pre-cleaned)
    if clean_text:
        processed_text = cleanText(text)
    else:
        processed_text = text
    
    # Transform using the same vectorizer from training
    text_vect = vectorizer.transform([processed_text])
    
    # Get prediction and probabilities
    prediction = model.predict(text_vect)[0]
    probabilities = model.predict_proba(text_vect)[0]
    
    # Get confidence for the predicted class
    confidence = probabilities[prediction] * 100
    
    # Also get confidence for both classes
    real_confidence = probabilities[0] * 100  # Class 0 = Real
    fake_confidence = probabilities[1] * 100  # Class 1 = Fake
    
    # Determine result
    result = "üü• FAKE" if prediction == 1 else "üü© REAL"
    
    return {
        'prediction': result,
        'confidence': confidence,
        'real_confidence': real_confidence,
        'fake_confidence': fake_confidence,
        'processed_text': processed_text[:100] + '...' if len(processed_text) > 100 else processed_text
    }

# Test with various news articles
print("üß™ TESTING FIXED PREDICTION FUNCTION")
print("="*60)

test_articles = [
    # Should be REAL
    "ISRO successfully launches another PSLV mission for Earth observation satellites to monitor climate change and agricultural patterns.",
    
    # Should be REAL  
    "Scientists at MIT develop new breakthrough in quantum computing technology that could revolutionize data processing and encryption methods.",
    
    # Should be REAL
    "Stock markets show steady growth amid positive economic indicators and strong corporate earnings reports for the third quarter.",
    
    # Should be FAKE
    "Drinking Dettol cures all known diseases including cancer and COVID-19, says viral WhatsApp message forwarded by millions.",
    
    # Should be FAKE
    "Local man discovers aliens in his backyard, government covers it up to prevent mass panic among citizens worldwide.",
    
    # Should be FAKE
    "Scientists prove that eating chocolate for breakfast makes you lose weight instantly without any exercise or diet changes.",
]

# Test each article
for i, article in enumerate(test_articles, 1):
    print(f"\nüì∞ Test Article {i}:")
    print(f"Text: {article[:80]}...")
    
    result = predict_news_fixed(article)
    
    print(f"ü§ñ Prediction: {result['prediction']}")
    print(f"üìä Confidence: {result['confidence']:.2f}%")
    print(f"üìà Real: {result['real_confidence']:.2f}% | Fake: {result['fake_confidence']:.2f}%")
    print(f"üîß Processed: {result['processed_text'][:60]}...")

# Additional debugging - test with pre-cleaned vs raw text
print("\n" + "="*60)
print("üîç DEBUGGING: RAW vs CLEANED TEXT COMPARISON")
print("="*60)

sample_text = "ISRO successfully launches PSLV mission for Earth observation."
print(f"Original text: {sample_text}")

# Test with cleaning
result_cleaned = predict_news_fixed(sample_text, clean_text=True)
print(f"With cleaning: {result_cleaned['prediction']} ({result_cleaned['confidence']:.2f}%)")

# Test without cleaning (if text is already processed)
cleaned_manually = cleanText(sample_text)
result_no_clean = predict_news_fixed(cleaned_manually, clean_text=False)
print(f"Pre-cleaned: {result_no_clean['prediction']} ({result_no_clean['confidence']:.2f}%)")

print(f"Cleaned text: '{cleaned_manually}'")

# Test with a sample from your actual training data to verify
print("\n" + "="*60)
print("üî¨ VERIFICATION: Testing with training data format")
print("="*60)

# Load a sample from your cleaned dataset to verify
import pandas as pd
try:
    df_sample = pd.read_csv('Notebooks/CleanedData.csv')
    df_sample = df_sample.drop(columns=['Unnamed: 0'], axis=1)
    
    # Test with actual training samples
    real_sample = df_sample[df_sample['label'] == 0]['content'].iloc[0]
    fake_sample = df_sample[df_sample['label'] == 1]['content'].iloc[0]
    
    print("Testing with REAL training sample:")
    result_real = predict_news_fixed(real_sample, clean_text=False)  # Already cleaned
    print(f"Prediction: {result_real['prediction']} ({result_real['confidence']:.2f}%)")
    
    print("\nTesting with FAKE training sample:")
    result_fake = predict_news_fixed(fake_sample, clean_text=False)  # Already cleaned
    print(f"Prediction: {result_fake['prediction']} ({result_fake['confidence']:.2f}%)")
    
except Exception as e:
    print(f"Could not load training data: {e}")

# Simple prediction function for easy use
def quick_predict(text):
    """Simple wrapper for quick predictions"""
    result = predict_news_fixed(text)
    return f"{result['prediction']} ({result['confidence']:.1f}% confident)"

print("\n" + "="*60)
print("üöÄ QUICK TEST FUNCTION")
print("="*60)

quick_tests = [
    "Breaking: Scientists discover cure for aging",
    "NASA announces successful Mars rover landing",
    "Local weather forecast predicts rain tomorrow"
]

for text in quick_tests:
    print(f"'{text}' ‚Üí {quick_predict(text)}")